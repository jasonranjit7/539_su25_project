# MNIST Digit Classification (Team 8)

This project explores handwritten digit recognition using the MNIST dataset. We implement a fully connected neural network (MLP) with a **manually implemented SGD optimizer with momentum**, and compare it with **PyTorchâ€™s built-in optimizers** and **CNN architectures** to evaluate performance, convergence, and generalizability.

---

## Team Members

- **Jason Ranjit Joseph Rajasekar**  
  ECE Department, Graduate Student  
  josephrajase@wisc.edu

- **Hae Seung Pyun**  
  Computer Science, Undergraduate  
  hpyun2@wisc.edu

- **Emma Vigy**  
  Computer Science, Undergraduate  
  evigy@wisc.edu

---

## Project Structure

```
mnist-digit-recognition/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ mlp.py              # MLP architecture
â”‚   â””â”€â”€ cnn.py              # CNN architecture
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train_mlp_manual.py # Manual SGD with momentum
â”‚   â”œâ”€â”€ train_mlp_builtin.py# PyTorch optimizer (MLP)
â”‚   â”œâ”€â”€ train_cnn.py        # CNN + PyTorch optimizer
â”‚   â””â”€â”€ evaluate.py         # Confusion matrix, predictions
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ accuracy_plots.png
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â””â”€â”€ mlp_manual.pth      # Saved model weights
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## Objective

Our goals:
- Implement **manual SGD with momentum** from scratch.
- Train a basic MLP on MNIST using this optimizer.
- Compare performance with:
  - PyTorch's built-in SGD and Adam
  - A simple convolutional neural network (CNN)
- Visualize accuracy, loss, and confusion matrices.
- Evaluate generalization across models.

---

## Models

### 1. MLP (Fully Connected)
- Input: 784 (28Ã—28) flattened image  
- Hidden Layers: 100 â†’ 50 neurons (ReLU)  
- Output: 10 classes (digits 0â€“9)

### 2. CNN
- Conv â†’ ReLU â†’ Pool â†’ Conv â†’ ReLU â†’ Pool â†’ FC â†’ FC  
- Standard CNN architecture for digit recognition.

---

## How to Run

### 1. Clone the Repository

```bash
git clone https://github.com/jasonranjit7/539_su25_project.git
cd mnist-digit-recognition
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Train Models

```bash
python src/train_mlp_manual.py         # Manual SGD
python src/train_mlp_builtin.py        # PyTorch SGD
python src/train_cnn.py                # CNN with Adam
```

### 4. Evaluate

```bash
python src/evaluate.py
```

---

## ðŸ§º Results Summary

| Model              | Optimizer     | Test Accuracy |
|-------------------|---------------|---------------|
| MLP (manual SGD)  | Manual SGD    | ~98.2%        |
| MLP (PyTorch SGD) | PyTorch SGD   | ~97.1%        |
| CNN               | PyTorch Adam  | ~99.2%        |

See:
- `results/accuracy_plots.png` for training curves  
- `results/confusion_matrix.png` for evaluation metrics  

---

## References

- LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). Gradient-based learning applied to document recognition. *Proceedings of the IEEE*, 86(11), 2278â€“2324.  
- [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)  
- [MNIST Dataset â€“ Kaggle](https://www.kaggle.com/datasets/hojjatk/mnist-dataset)

---
